ops.py, myACT\gact\gact\quantizer.py



![1736678079967](image/readme/1736678079967.png)

训练导致内存溢出是在这里的，忘记当时是怎么解决的了，但是大概来讲就是这里张量变化的时候id的处理有问题用了错误的索引去找tensor对应下标 的值，这里是cuda处理完的tensor的形状和id对不上了，这里topk之前先展开一下，展开成一维的再取就没有溢出问题了。

![1736677970281](image/readme/1736677970281.png)

自定义的hash函数是静态存储的，每次hash函数数量不够的时候重新构造一个随机的，然后添加进去，数量够的话就用已有的.

这里的hash函数是用来做tensor间的相似性的。

![1736681649263](image/readme/1736681649263.png)

这里是tensor内的相似性的实现。


后续可继续优化：

如果可以的话，tensor内部的相似性在cuda代码里实现应该可以进一步优化。

相似的量化结果只保留一份，进一步优化内存。

相似性这里只用在量化结果上，普通的tensor、前向反向也可以用，进一步优化计算开销。
